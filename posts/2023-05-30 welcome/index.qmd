---
title: "Welcome to Bayesically Speaking"
description: |
  Hi everyone! This is the first post of Bayesically Speaking, so get your seatbelt on and get ready to join me on this ride!
author: "Matías Castillo-Aguilar"
date: "2023-05-30"
title-block-banner: title_block.jpeg 
categories: [news]
bibliography: ref.bib
image: "body_1.jpeg"
toc: true
editor_options: 
  chunk_output_type: console
---

# Hello stranger

First of all, welcome to the first post of "Bayesically Speaking" (which, in case you haven't noticed, is a word play between "Basically Speaking" and the (hopefully) well-known Bayes' theorem), and although the web is offline at the time of writing this article, I find myself following the advice of all those people who encouraged me to trust my instinct and dare to do what I have always wanted: to be able to transmit the thrill of using science as a tool to know and understand the reality that surrounds us and that we perceive in a limited way through our senses.

For years, my interests have revolved around understanding the world through the lens of statistics, particularly as a tool to better understand and quantify the relationships between the moving parts that make up many health outcomes. Another aspect that I find fascinating is how certain variables can go unnoticed when viewed separately, but when viewed together can have radically different behaviors. 

![This phenomenom is better known as [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox).](simpson.png){.rounded .img-fluid}

## The statistics toolbox

Within the toolbox of conventional statistics, there are some commonly used tests that are useful when we want to compare two or more groups (t-test and ANOVA), or even to assess whether two variables are related in some way (correlations and regression). These have the advantage that they are relatively easy to use and understand, however, like everything else, they have their own limitations.

The main limitations of conventional tools is the lack of flexibility to handle common scenarios in real-life data, such as variables with asymmetric distributions, non-linear relationships, unbalanced groups, heterogeneous variance, extreme values or repeated measurements with loss of follow-up, etc.

## There are alternatives

To address these limitations there are multiple non-parametric alternatives to these tests, however, given the lack of distributional parameters that are estimated, it is difficult to generate inferences about their behavior when we want to extrapolate on new data. Like everything else, nothing good comes without its limitations.

There are many models, as well as other tools that can offer assistance when analyzing data with special properties, such as neural networks or random forest models, which can help us to fit unconventional data efficiently, but which sacrifice simplicity and interpretability for flexibility. These are commonly known as "black box" models since we rarely know what is going on under the hood with our data, we only see what comes out. We will not delve too deeply into these models, as they are beyond the scope of this article.

![Photo from [Dan Cristian Pădureț](https://unsplash.com/pt-br/@dancristianpaduret?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) at [Unsplash](https://unsplash.com/es/fotos/h3kuhYUCE9A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).](body_1.jpeg){.rounded .img-fluid}

Given these challenges, there is a pressing need to incorporate previous knowledge into our inference, aligning with the way human knowledge is constructed. As humans, our understanding of the world is constantly shaped by our experiences and prior beliefs. This is where bayesian statistics come into play.

Bayesian statistics offer several benefits over frequentist statistics. Firstly, they provide a coherent framework for incorporating prior information into our analysis, allowing us to update our beliefs in a systematic manner. Additionally, Bayesian statistics allow for the quantification of uncertainty through probability distributions, providing a more intuitive and interpretable way to express our findings and degree of certainty.

```{r}
#| include: false
library(ggplot2)
```

Let's consider the following example: Imagine we have a belief that when tossing a coin, there is a higher probability of it landing on heads. Our prior knowledge stems from a previous experiment where, out of 15 coin tosses, 10 resulted in heads. This implies a calculated probability of 2/3 or 66.6% based on the previous data.

With this information we decide to explore further, we conduct our own experiment. To our astonishment, out of 15 tosses, we observe a remarkable outcome: 13 tails and only 2 heads! This result suggests that the probability of getting heads based solely on our new data is a mere 2/15 or 13.3%. However, it would be unwise to dismiss the prior evidence in light of these conflicting results. Incorporating these findings into our body of knowledge becomes even more crucial as we strive to gain a deeper understanding of the combined effect.

This example highlights the essence of Bayesian statistics—where prior beliefs are updated based on new evidence to refine our understanding of the underlying truth. Despite the seemingly contradictory outcomes, Bayesian inference allows us to incorporate both the prior knowledge and the new data to derive a more comprehensive and nuanced view of the situation. By embracing Bayesian principles, we unlock the potential to harness the power of statistics and enhance our insights into the complexities of the world around us.

```{r}
#| echo: false
#| fig-format: svg
#| fig-align: center
#| fig-cap: "Graphical representation of how the posterior probability represents the combination of both, the data and the prior knowledge (or evidence)"

data = function(x) {
  p = dbeta(x, 2, 13); p
}
prior = function(x) {
  p = dbeta(x, 10, 5); p
}
posterior = function(x) {
  p_fun = function(i) data(i) * prior(i) 
  const = integrate(p_fun, 0L, 1L)$value # This way it can sum integrate to 1
  p = p_fun(x); p / const
}

col_pal <- c(Prior = "#DEEBF7", 
             Data = "#3182BD", 
             Posterior = "#9ECAE1")

ggplot() +
  stat_function(aes(fill = "Data"), fun = data, geom = "density", alpha = 1/2) +
  stat_function(aes(fill = "Prior"), fun = prior, geom = "density", alpha = 1/2) +
  stat_function(aes(fill = "Posterior"), fun = posterior, geom = "density", alpha = 1/2) +
  labs(fill = "", y = "Density", x = "Probability of getting heads") +
  scale_fill_manual(values = col_pal, aesthetics = "fill") +
  scale_x_continuous(labels = scales::label_percent(), 
                     limits = c(0,1)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 6)) +
  see::theme_modern() +
  theme(legend.position = "top",
        legend.spacing.x = unit(3, "mm")) +
  geom_curve(aes(x = .81, y = 4.1, xend = .69232, yend = 3.425), curvature = .4,
               arrow = arrow(length = unit(1/3, "cm"), angle = 20)) +
  geom_text(aes(x = .9, y = 4.1, label = "beta(10,5)")) +
  geom_curve(aes(x = .2, y = 5.9, xend = .07693, yend = 5.45), curvature = .4,
               arrow = arrow(length = unit(1/3, "cm"), angle = 20)) +
  geom_text(aes(x = .29, y = 5.9, label = "beta(2,13)")) +
  geom_curve(aes(x = .5, y = 5, xend = .3847, yend = 4.4), curvature = .4,
               arrow = arrow(length = unit(1/3, "cm"), angle = 20)) +
  geom_text(aes(x = .61, y = 5, label = "Mean: 39%"))

```

Furthermore, the bayesian inference workflow of incorporating new evidence to update prior beliefs closely resembles the way humans process and learn from new information. Both involve incorporating prior knowledge, updating beliefs with new evidence, weighing the credibility of evidence, engaging in an iterative learning process, considering uncertainty, and exhibiting flexibility and adaptability. This parallel highlights the natural compatibility between bayesian inference and the way humans assimilate and process new information and experience.

As in words of @gelman2013philosophy.

> A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics.

However, it's crucial to recognize that while more complex or flexible tools offer advantages, they also come with their own limitations. To comprehend the appropriate application of each statistical tool, we must understand these limitations.

For instance, one may question why bayesian statistics were not as popular in the past as they are now, given their powerful nature. The answer lies in the computational challenges associated with implementing bayesian inference. Many algorithms that utilize bayesian inference rely on simulating the full parameter space and calculating the probability of each possible outcome based on the available data. However, such computations and simulation routines were not feasible years ago, unlike the capabilities we have today. The advancements in computing power and simulation techniques have made it possible to handle the complex calculations required for bayesian analysis, contributing to the increased popularity and widespread adoption of bayesian statistics in recent times.

![Photo from [Joao Alexandre Paulo](https://unsplash.com/de/@alexandrecpaulo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) at [Unsplash](https://unsplash.com/es/fotos/qA005Vbp7jk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).](body_2.jpeg){.rounded .float-start}

As an enthusiastic self-learner, even though I'm not a statistician, I'm eager to share the potential that these tools hold for understanding real-world phenomena, delving into the world of statistics, particularly through the lens of Bayesian inference, opens up exciting avenues for understanding the complexities of our world. By incorporating prior knowledge, updating beliefs with new evidence, and embracing uncertainty, we can unravel profound insights into health, well-being, and various phenomena.

The beauty lies in the interplay between statistical tools and our inherent human capacity to learn, adapt, and refine our understanding. So, let's embark on this journey together, exploring the potential of statistics and its transformative power to better understand the intricacies of our reality.

Get ready to unlock a deeper comprehension of the world around us and seize the immense opportunities that await us. Together, let's embrace the remarkable world of statistics with enthusiasm and an insatiable hunger for knowledge.
