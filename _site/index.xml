<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Bayesically Speaking</title>
<link>https://bayesically-speaking.com/index.html</link>
<atom:link href="https://bayesically-speaking.com/index.xml" rel="self" type="application/rss+xml"/>
<description>The place where statistics, coffee and bayes theorem come toghether</description>
<generator>quarto-1.2.269</generator>
<lastBuildDate>Sat, 10 Jun 2023 03:00:00 GMT</lastBuildDate>
<item>
  <title>Welcome to Bayesically Speaking</title>
  <dc:creator>Matías Castillo-Aguilar</dc:creator>
  <link>https://bayesically-speaking.com/posts/2023-05-30 welcome/index.html</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://bayesically-speaking.com/posts/2023-05-30 welcome/hello_world.jpeg" class="rounded img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Photo from <a href="https://unsplash.com/@jontyson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jon Tyson</a> at <a href="https://unsplash.com/es/fotos/tangfe8KQdw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption><p></p>
</figure>
</div>
<section id="hello-stranger" class="level1 page-columns page-full">
<h1>Hello stranger</h1>
<p>First of all, welcome to the first post of “Bayesically Speaking” (which, in case you haven’t noticed, is a word play between “Basically Speaking” and the (hopefully) well-known Bayes’ theorem), and although the web is offline at the time of writing this article, I find myself following the advice of all those people who encouraged me to trust my instinct and dare to do what I have always wanted: to be able to transmit the thrill of using science as a tool to know and understand the reality that surrounds us and that we perceive in a limited way through our senses.</p>
<p>For years, my interests have revolved around understanding the world through the lens of statistics, particularly as a tool to better understand and quantify the relationships between the moving parts that make up many health outcomes. Another aspect that I find fascinating is how certain variables can go unnoticed when viewed separately, but when viewed together can have radically different behaviors.</p>
<div class="cell page-columns page-full">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">sim_data <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">simulate_simpson</span>(<span class="at" style="color: #657422;">n =</span> <span class="dv" style="color: #AD0000;">100</span>, </span>
<span id="cb1-2">                             <span class="at" style="color: #657422;">difference =</span> <span class="dv" style="color: #AD0000;">2</span>, </span>
<span id="cb1-3">                             <span class="at" style="color: #657422;">groups =</span> <span class="dv" style="color: #AD0000;">4</span>, </span>
<span id="cb1-4">                             <span class="at" style="color: #657422;">r =</span> .<span class="dv" style="color: #AD0000;">7</span>) <span class="sc" style="color: #5E5E5E;">|&gt;</span> </span>
<span id="cb1-5">  <span class="fu" style="color: #4758AB;">as.data.table</span>()</span>
<span id="cb1-6"></span>
<span id="cb1-7">sim_data[, Group <span class="sc" style="color: #5E5E5E;">:</span><span class="er" style="color: #AD0000;">=</span> <span class="fu" style="color: #4758AB;">factor</span>(Group, </span>
<span id="cb1-8">                           <span class="at" style="color: #657422;">levels =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"G_1"</span>,<span class="st" style="color: #20794D;">"G_2"</span>,<span class="st" style="color: #20794D;">"G_3"</span>,<span class="st" style="color: #20794D;">"G_4"</span>),</span>
<span id="cb1-9">                           <span class="at" style="color: #657422;">labels =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"Placebo"</span>, <span class="st" style="color: #20794D;">"Low dose"</span>, <span class="st" style="color: #20794D;">"Medium dose"</span>, <span class="st" style="color: #20794D;">"High dose"</span>))]</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="fu" style="color: #4758AB;">ggplot</span>(sim_data, <span class="fu" style="color: #4758AB;">aes</span>(V1, V2, <span class="at" style="color: #657422;">col =</span> Group)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-12">  <span class="fu" style="color: #4758AB;">geom_point</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-13">  <span class="fu" style="color: #4758AB;">geom_smooth</span>(<span class="at" style="color: #657422;">method =</span> <span class="st" style="color: #20794D;">"lm"</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-14">  <span class="fu" style="color: #4758AB;">geom_smooth</span>(<span class="at" style="color: #657422;">method =</span> <span class="st" style="color: #20794D;">"lm"</span>, <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">group =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">col =</span> <span class="cn" style="color: #8f5902;">NULL</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-15">  <span class="fu" style="color: #4758AB;">scale_color_brewer</span>(<span class="at" style="color: #657422;">type =</span> <span class="st" style="color: #20794D;">"qual"</span>, <span class="at" style="color: #657422;">palette =</span> <span class="dv" style="color: #AD0000;">2</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-16">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Time exposure"</span>, <span class="at" style="color: #657422;">y =</span> <span class="fu" style="color: #4758AB;">expression</span>(Delta<span class="sc" style="color: #5E5E5E;">*</span><span class="st" style="color: #20794D;">"TNF-"</span><span class="sc" style="color: #5E5E5E;">*</span>alpha)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-17">  <span class="fu" style="color: #4758AB;">theme_classic</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb1-18">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">legend.position =</span> <span class="st" style="color: #20794D;">"top"</span>)</span></code></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://bayesically-speaking.com/posts/2023-05-30 welcome/index_files/figure-html/unnamed-chunk-2-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">In this example, the whole sample correlation is about -0.71 (meaning a negative relationship), but the within group correlation is 0.7 (the exact opposite effect). This phenomenom is better known as Simpson’s Paradox.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<section id="the-statistics-toolbox" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-statistics-toolbox">The statistics toolbox</h2>
<p>Within the statistics toolbox, we have commonly used tests like t-tests, ANOVA, correlations, and regression. These methods have their advantages, as they are relatively easy to use and understand. However, like any other tool, they also have their limitations. For instance, they struggle with scenarios involving variables with asymmetric distributions, non-linear relationships, unbalanced groups, heterogeneous variance, extreme values, or repeated measurements with loss of follow-up.</p>
<p>To address these limitations, non-parametric alternatives have been developed. These approaches offer flexibility but make it challenging to extrapolate inferences to new data due to the lack of distributional parameters. Other models, such as neural networks or random forest models, provide assistance when analyzing data with special properties. However, they often sacrifice simplicity and interpretability for increased flexibility and are commonly referred to as “black box” models.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://bayesically-speaking.com/posts/2023-05-30 welcome/body_1.jpeg" class="rounded img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Just between us, I only put this picture because it looked cool. Photo from <a href="https://unsplash.com/pt-br/@dancristianpaduret?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Dan Cristian Pădureț</a> at <a href="https://unsplash.com/es/fotos/h3kuhYUCE9A?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption><p></p>
</figure>
</div>
<p>Despite the availability of these alternative methods, there is still a pressing need to incorporate previous knowledge and align with the way human understanding is constructed. As humans, our perception of the world is shaped by experiences and prior beliefs. This is where Bayesian statistics come into play.</p>
<p>Bayesian statistics offer several advantages over classical statistics (also known as “frequentist”). Firstly, they provide a coherent framework for incorporating prior information into our analysis, enabling us to update our beliefs systematically. Additionally, Bayesian statistics allow us to quantify uncertainty through probability distributions, offering a more intuitive and interpretable way to express our findings and the degree of certainty.</p>
</section>
</section>
<section id="the-toss-of-a-coin" class="level1 page-columns page-full">
<h1>The toss of a coin</h1>
<p>Let’s consider the following example: Imagine we have a belief that when tossing a coin, there is a higher probability of it landing on heads. Our prior knowledge stems from a previous experiment where, out of 15 coin tosses, 10 resulted in heads. This implies a calculated probability of <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B10%7D%7B15%7D%20%5Capprox%200.66"> based on the previous data.</p>
<p>With this information we decide to explore further, we conduct our own experiment. To our astonishment, out of 15 tosses, we observe un unexpected outcome: 13 tails and only 2 heads! This result suggests that the probability of getting heads based solely on our new data is a mere <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B2%7D%7B15%7D%20%5Capprox%200.13">. However, it would be unwise to dismiss the prior evidence in light of these conflicting results. Incorporating these findings into our body of knowledge becomes even more crucial as we strive to gain a deeper understanding of the combined effect.</p>
<section id="computing-the-posterior" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="computing-the-posterior">Computing the posterior</h2>
<p>To estimate the posterior probability of getting heads after tossing a coin, we can use the Bayesian framework. Let’s denote the probability of getting heads in a coin toss as <img src="https://latex.codecogs.com/png.latex?P(H)">.</p>
<p>According to the information provided, we have the prior probability of <img src="https://latex.codecogs.com/png.latex?P(H)"> estimated from an independent experiment as 10 heads out of 15 tosses. This can be written as a Beta distribution:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This symbol “<img src="https://latex.codecogs.com/png.latex?%5Csim">” means <em>distributed as</em></p>
</div></div><p><img src="https://latex.codecogs.com/png.latex?%0AP(H)%20%5Csim%20Beta(10,%205)%0A"></p>
<p>Here, the Beta distribution parameters are (10, 5) since we had 10 heads and 5 tails in the prior experiment.</p>
<p>Now, a new experiment with the same 15 tosses gives us 2 heads. To update our prior belief, we can use this information to calculate the posterior probability which can be expressed as follow:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This symbol “<img src="https://latex.codecogs.com/png.latex?%5Cpropto">” means <em>proportional to</em></p>
</div></div><p><img src="https://latex.codecogs.com/png.latex?%0AP(H%20%7C%20Data)%20%5Cpropto%20P(Data%20%7C%20H)%20%5Ctimes%20P(H)%0A"></p>
<p>Which is equivalent as saying:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0APosterior%20%5Cpropto%20Likelihood%20%5Ctimes%20Prior%0A"></p>
<p>To calculate the posterior probability, we need to normalize the product of the likelihood and prior, which involves integrating over all possible values of H. However, in this case, we can use a shortcut because the prior distribution is conjugate to the binomial distribution, so the posterior distribution will also follow a Beta distribution:</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
About normalization
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The product of both the prior and the likelihood maintains the same shape as the final posterior probability distribution, indicated by the “proportional to” (<img src="https://latex.codecogs.com/png.latex?%5Cpropto">) in the previous equation. However, this raw product does not sum up to 1, making it an improper probability density function. To rectify this, the raw product needs to be normalized using integration or simulation in most cases.</p>
</div>
</div>
</div>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(H%20%7C%20Data)%20%5Csim%20Beta(10%20+%202,%205%20+%2013)%0A"></p>
<p>After incorporating the data from the new experiment, the parameters of the Beta distribution become (12, 18) since we had 2 heads and 13 tails in the new experiment, meaning 12 heads and 18 tails in total.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
About conjugacy
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>When we choose a Beta distribution as our prior belief and gather new data from a coin toss, an intriguing property emerges: the posterior distribution also follows a Beta distribution. This property, known as conjugacy, offers a valuable advantage by simplifying calculations. It acts as a mathematical shortcut that saves time and effort, making the analysis more efficient and streamlined.</p>
</div>
</div>
</div>
<p>To calculate the posterior probability of getting heads, we can consider the mode (maximum) of the Beta distribution, which is <img src="https://latex.codecogs.com/png.latex?(a%20-%201)%20/%20(a%20+%20b%20-%202)">:</p>
<div class="text-center">
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%20P(H%20%7C%20Data)%20&amp;=%20(12%20-%201)%20/%20(12%20+%2018%20-%202)%20%5C%5C%20%20&amp;=%2011%20/%2028%20%5C%5C%20%20&amp;%5Capprox%200.39%20%5Cend%7Baligned%7D"></p>
</div>
<p>Therefore, the posterior probability of getting heads is approximately 39% when we consider all the available evidence.</p>
<div class="cell page-columns page-full">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Prior and Likelihood functions</span></span>
<span id="cb2-2">data <span class="ot" style="color: #003B4F;">=</span> <span class="cf" style="color: #003B4F;">function</span>(x, <span class="at" style="color: #657422;">to_log =</span> <span class="cn" style="color: #8f5902;">FALSE</span>) <span class="fu" style="color: #4758AB;">dbeta</span>(x, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">13</span>, <span class="at" style="color: #657422;">log =</span> to_log)</span>
<span id="cb2-3">prior <span class="ot" style="color: #003B4F;">=</span> <span class="cf" style="color: #003B4F;">function</span>(x, <span class="at" style="color: #657422;">to_log =</span> <span class="cn" style="color: #8f5902;">FALSE</span>) <span class="fu" style="color: #4758AB;">dbeta</span>(x, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="at" style="color: #657422;">log =</span> to_log)</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;"># Posterior</span></span>
<span id="cb2-6">posterior <span class="ot" style="color: #003B4F;">=</span> <span class="cf" style="color: #003B4F;">function</span>(x) {</span>
<span id="cb2-7">  p_fun <span class="ot" style="color: #003B4F;">=</span> <span class="cf" style="color: #003B4F;">function</span>(i) {</span>
<span id="cb2-8">    <span class="co" style="color: #5E5E5E;"># Operation is on log-scale merely for computing performance</span></span>
<span id="cb2-9">    <span class="co" style="color: #5E5E5E;"># and minimize rounding errors giving the small nature of</span></span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;"># probability density values at each interval.</span></span>
<span id="cb2-11">    i_log <span class="ot" style="color: #003B4F;">=</span> <span class="fu" style="color: #4758AB;">data</span>(i, <span class="at" style="color: #657422;">to_log =</span> <span class="cn" style="color: #8f5902;">TRUE</span>) <span class="sc" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">prior</span>(i, <span class="at" style="color: #657422;">to_log =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span>
<span id="cb2-12">    <span class="co" style="color: #5E5E5E;"># Then transformed back to get probabilities again</span></span>
<span id="cb2-13">    <span class="fu" style="color: #4758AB;">exp</span>(i_log)</span>
<span id="cb2-14">  }</span>
<span id="cb2-15">  </span>
<span id="cb2-16">  <span class="co" style="color: #5E5E5E;"># Then we integrate using base function `integrate`</span></span>
<span id="cb2-17">  const <span class="ot" style="color: #003B4F;">=</span> <span class="fu" style="color: #4758AB;">integrate</span>(<span class="at" style="color: #657422;">f =</span> p_fun, </span>
<span id="cb2-18">                    <span class="at" style="color: #657422;">lower =</span> 0L,  <span class="at" style="color: #657422;">upper =</span> 1L, </span>
<span id="cb2-19">                    <span class="at" style="color: #657422;">subdivisions =</span> <span class="fl" style="color: #AD0000;">1e3</span>L,</span>
<span id="cb2-20">                    <span class="at" style="color: #657422;">rel.tol =</span> .Machine<span class="sc" style="color: #5E5E5E;">$</span>double.eps)<span class="sc" style="color: #5E5E5E;">$</span>value</span>
<span id="cb2-21">  <span class="fu" style="color: #4758AB;">p_fun</span>(x) <span class="sc" style="color: #5E5E5E;">/</span> const</span>
<span id="cb2-22">}</span>
<span id="cb2-23"></span>
<span id="cb2-24"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Plotting phase</span></span>
<span id="cb2-25"></span>
<span id="cb2-26"><span class="do" style="color: #5E5E5E;
font-style: italic;">### Color palette</span></span>
<span id="cb2-27">col_pal <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="at" style="color: #657422;">Prior =</span> <span class="st" style="color: #20794D;">"#DEEBF7"</span>, </span>
<span id="cb2-28">             <span class="at" style="color: #657422;">Data =</span> <span class="st" style="color: #20794D;">"#3182BD"</span>, </span>
<span id="cb2-29">             <span class="at" style="color: #657422;">Posterior =</span> <span class="st" style="color: #20794D;">"#9ECAE1"</span>)</span>
<span id="cb2-30"><span class="do" style="color: #5E5E5E;
font-style: italic;">### Main plotting code</span></span>
<span id="cb2-31"><span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-32">  <span class="do" style="color: #5E5E5E;
font-style: italic;">#### Main probability density functions</span></span>
<span id="cb2-33">  <span class="fu" style="color: #4758AB;">stat_function</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">fill =</span> <span class="st" style="color: #20794D;">"Data"</span>), <span class="at" style="color: #657422;">fun =</span> data, <span class="at" style="color: #657422;">geom =</span> <span class="st" style="color: #20794D;">"density"</span>, <span class="at" style="color: #657422;">alpha =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-34">  <span class="fu" style="color: #4758AB;">stat_function</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">fill =</span> <span class="st" style="color: #20794D;">"Prior"</span>), <span class="at" style="color: #657422;">fun =</span> prior, <span class="at" style="color: #657422;">geom =</span> <span class="st" style="color: #20794D;">"density"</span>, <span class="at" style="color: #657422;">alpha =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-35">  <span class="fu" style="color: #4758AB;">stat_function</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">fill =</span> <span class="st" style="color: #20794D;">"Posterior"</span>), <span class="at" style="color: #657422;">fun =</span> posterior, <span class="at" style="color: #657422;">geom =</span> <span class="st" style="color: #20794D;">"density"</span>, <span class="at" style="color: #657422;">alpha =</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-36">  <span class="do" style="color: #5E5E5E;
font-style: italic;">#### Minor aesthetics tweaks</span></span>
<span id="cb2-37">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">fill =</span> <span class="st" style="color: #20794D;">""</span>, <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">"Density"</span>, <span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Probability of getting heads"</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-38">  <span class="fu" style="color: #4758AB;">scale_fill_manual</span>(<span class="at" style="color: #657422;">values =</span> col_pal, <span class="at" style="color: #657422;">aesthetics =</span> <span class="st" style="color: #20794D;">"fill"</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-39">  <span class="fu" style="color: #4758AB;">scale_x_continuous</span>(<span class="at" style="color: #657422;">labels =</span> scales<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">label_percent</span>(), </span>
<span id="cb2-40">                     <span class="at" style="color: #657422;">limits =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-41">  <span class="fu" style="color: #4758AB;">scale_y_continuous</span>(<span class="at" style="color: #657422;">expand =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">0</span>), <span class="at" style="color: #657422;">limits =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">6.5</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-42">  see<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">theme_modern</span>() <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-43">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">legend.position =</span> <span class="st" style="color: #20794D;">"top"</span>,</span>
<span id="cb2-44">        <span class="at" style="color: #657422;">legend.spacing.x =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">3</span>, <span class="st" style="color: #20794D;">"mm"</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-45">  <span class="do" style="color: #5E5E5E;
font-style: italic;">#### Arrows</span></span>
<span id="cb2-46">  <span class="fu" style="color: #4758AB;">geom_curve</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">81</span>, <span class="at" style="color: #657422;">y =</span> <span class="fl" style="color: #AD0000;">4.1</span>, <span class="at" style="color: #657422;">xend =</span> .<span class="dv" style="color: #AD0000;">69232</span>, <span class="at" style="color: #657422;">yend =</span> <span class="fl" style="color: #AD0000;">3.425</span>), <span class="at" style="color: #657422;">curvature =</span> .<span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb2-47">               <span class="at" style="color: #657422;">arrow =</span> <span class="fu" style="color: #4758AB;">arrow</span>(<span class="at" style="color: #657422;">length =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">3</span>, <span class="st" style="color: #20794D;">"cm"</span>), <span class="at" style="color: #657422;">angle =</span> <span class="dv" style="color: #AD0000;">20</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-48">  <span class="fu" style="color: #4758AB;">geom_text</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">9</span>, <span class="at" style="color: #657422;">y =</span> <span class="fl" style="color: #AD0000;">4.1</span>, <span class="at" style="color: #657422;">label =</span> <span class="st" style="color: #20794D;">"Beta(10,5)"</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-49">  <span class="fu" style="color: #4758AB;">geom_curve</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">2</span>, <span class="at" style="color: #657422;">y =</span> <span class="fl" style="color: #AD0000;">5.9</span>, <span class="at" style="color: #657422;">xend =</span> .<span class="dv" style="color: #AD0000;">07693</span>, <span class="at" style="color: #657422;">yend =</span> <span class="fl" style="color: #AD0000;">5.45</span>), <span class="at" style="color: #657422;">curvature =</span> .<span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb2-50">               <span class="at" style="color: #657422;">arrow =</span> <span class="fu" style="color: #4758AB;">arrow</span>(<span class="at" style="color: #657422;">length =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">3</span>, <span class="st" style="color: #20794D;">"cm"</span>), <span class="at" style="color: #657422;">angle =</span> <span class="dv" style="color: #AD0000;">20</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-51">  <span class="fu" style="color: #4758AB;">geom_text</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">29</span>, <span class="at" style="color: #657422;">y =</span> <span class="fl" style="color: #AD0000;">5.85</span>, <span class="at" style="color: #657422;">label =</span> <span class="st" style="color: #20794D;">"Beta(2,13)"</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-52">  <span class="fu" style="color: #4758AB;">geom_curve</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">5</span>, <span class="at" style="color: #657422;">y =</span> <span class="dv" style="color: #AD0000;">5</span>, <span class="at" style="color: #657422;">xend =</span> .<span class="dv" style="color: #AD0000;">3847</span>, <span class="at" style="color: #657422;">yend =</span> <span class="fl" style="color: #AD0000;">4.4</span>), <span class="at" style="color: #657422;">curvature =</span> .<span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb2-53">               <span class="at" style="color: #657422;">arrow =</span> <span class="fu" style="color: #4758AB;">arrow</span>(<span class="at" style="color: #657422;">length =</span> <span class="fu" style="color: #4758AB;">unit</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">3</span>, <span class="st" style="color: #20794D;">"cm"</span>), <span class="at" style="color: #657422;">angle =</span> <span class="dv" style="color: #AD0000;">20</span>)) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb2-54">  <span class="fu" style="color: #4758AB;">geom_text</span>(<span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> .<span class="dv" style="color: #AD0000;">55</span>, <span class="at" style="color: #657422;">y =</span> <span class="dv" style="color: #AD0000;">5</span>, <span class="at" style="color: #657422;">label =</span> <span class="st" style="color: #20794D;">"≈ 39%"</span>))</span></code></pre></div>
</details>
<div class="cell-output-display page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://bayesically-speaking.com/posts/2023-05-30 welcome/index_files/figure-html/unnamed-chunk-3-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Graphical representation of the posterior probability as the combination of both the data and the prior evidence</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="practical-implications" class="level1 page-columns page-full">
<h1>Practical implications</h1>
<p>This example truly showcases the power of Bayesian statistics, where our prior beliefs are transformed by new evidence, allowing us to gain deeper insights into the world. Despite the unexpected twists and turns, Bayesian inference empowers us to blend prior knowledge with fresh data, creating a rich tapestry of understanding. By embracing the spirit of Bayesian principles, we open doors to the exciting potential of statistics and embark on a captivating journey to unravel the complexities of our reality.</p>
<p>What’s even more fascinating is how closely the Bayesian inference process aligns with our natural way of learning and growing. Just like we integrate prior knowledge, weigh new evidence, and embrace uncertainty in our daily lives, Bayesian inference beautifully mirrors our innate cognitive processes. It’s a dynamic dance of assimilating information, refining our understanding, and embracing the inherent uncertainties of life. This remarkable synergy between Bayesian inference and our innate curiosity has been a driving force behind the rise and success of Bayesian statistics in both theory and practice.</p>
<p>As <span class="citation" data-cites="gelman2013philosophy">Gelman and Shalizi (2013)</span> eloquently states, “A substantial school in the philosophy of science identifies Bayesian inference with inductive inference and even rationality as such, and seems to be strengthened by the rise and practical success of Bayesian statistics.”</p>
<div class="no-row-height column-margin column-container"><div id="ref-gelman2013philosophy" class="csl-entry">
Gelman, Andrew, and Cosma Rohilla Shalizi. 2013. <span>“Philosophy and the Practice of Bayesian Statistics.”</span> <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1): 8–38.
</div></div><p>However, it’s important to acknowledge that while advanced statistical tools offer incredible possibilities, they also come with their own set of limitations. To make the most of these tools, we need to understand their boundaries and make informed choices about their applications.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://bayesically-speaking.com/posts/2023-05-30 welcome/body_2.jpeg" class="rounded img-float img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Photo from <a href="https://unsplash.com/de/@nasa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NASA</a> at <a href="https://unsplash.com/es/fotos/Q1p7bh3SHj8?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption><p></p>
</figure>
</div>
<section id="from-past-to-future" class="level2">
<h2 class="anchored" data-anchor-id="from-past-to-future">From past to future</h2>
<p>Imagine a time not too long ago when Bayesian statistics were not as prevalent as they are today. The computational challenges posed significant hurdles, limiting our ability to fully embrace their potential. But thanks to the rapid advancement of computing power and simulation techniques, the statistical landscape has undergone a revolution. We now find ourselves in an exciting era where complex Bayesian analysis is accessible to all. It’s like having a superpower in the palm of our hands—an empowering time where our statistical prowess can thrive and conquer new frontiers.</p>
<p>As passionate self-learners on this thrilling statistical journey, even without a formal statistician’s hat, we can’t help but feel an overwhelming excitement to share the vast potential of these tools for unraveling real-world phenomena. Delving into the world of statistics, especially through the lens of Bayesian inference, opens up a universe of captivating possibilities. By melding prior knowledge with fresh evidence and embracing the enigmatic realm of uncertainty, we can uncover profound insights into health, well-being, and the wondrous phenomena that shape our lives.</p>
<p>So, fellow adventurers, let’s ignite our curiosity, embrace our thirst for knowledge, and embark on this exhilarating voyage together. With statistics as our compass, we will navigate the complexities of our reality, expanding our understanding and seizing the extraordinary opportunities that await us.</p>
<p>Get ready to experience a world that’s more vivid, more nuanced, and more awe-inspiring than ever before. Together, let’s dive into the captivating realm of statistics, fueled by enthusiasm and a passion for discovery.</p>



</section>
</section>

 ]]></description>
  <category>news</category>
  <guid>https://bayesically-speaking.com/posts/2023-05-30 welcome/index.html</guid>
  <pubDate>Sat, 10 Jun 2023 03:00:00 GMT</pubDate>
  <media:content url="https://bayesically-speaking.com/posts/2023-05-30 welcome/body_1.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
